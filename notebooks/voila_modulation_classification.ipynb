{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, warnings\n",
    "from pynq import PL\n",
    "from pynq import Overlay\n",
    "from pynq import allocate\n",
    "import numpy as np\n",
    "from AMCCNN import AMCCNN\n",
    "import scipy.io\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol = Overlay(\"amc_dma_rfsoc.bit\")\n",
    "dma = ol.axi_dma_0\n",
    "amc = ol.amc_cnn_0\n",
    "testset_file = 'AMC_dataset_demo.pkl'\n",
    "X = pickle.load(open(testset_file, 'rb'), encoding='latin')\n",
    "from AMCWidget import AMCWidget\n",
    "amc_widget=AMCWidget(X, amc, dma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming-CNN FPGA Architecture for Communications-based Applications\n",
    "----\n",
    "This demonstration will present a modulation classification application for wireless communications modulation schemes running on a **AMD-Xilinx RFSoC 2x2 development board**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modulation Classification\n",
    "This demo intends to showcase the proposed streaming-CNN architecture running on an RFSoC 2x2 development board. Currently, the IP exists on-chip with inputs transferred via AXI4-Stream from the Processing System to Programmable Logic with future aims to connect directly to RF Data Converters on the RFSoC.\n",
    "\n",
    "**Modulation Classification** is the task of indentifying what modulation scheme a received signal has been encoded with. The possible modulation schemes are: \n",
    "* 8PSK\n",
    "* BPSK\n",
    "* CPFSK\n",
    "* GFSK\n",
    "* PAM14\n",
    "* QAM16\n",
    "* QAM64\n",
    "* QPSK\n",
    "\n",
    "## Neural Network Structure\n",
    "\n",
    "![](NN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture\n",
    "The CNN architecture has been built to support constant streaming inputs similar to how a classical communications pipeline is built with filters processing a stream of samples. This architecture aims to allow deep learning solutions to be inserted within an already existing communications pipeline. We assume samples from the air are constantly being received and this architecture has been built to support a stream without interruptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Input Sample Restructure\n",
    "\n",
    "To facilitate a streaming input convention, the order in which the neural network calculations are processed must be revisited. In a typical sliding window convolutional layer approach, the kernel weights may be processed over the input data multiple times. To simplify the calculations being performed on chip, the input data is transformed into a matrix equivalent of the sliding kernel approach. Similarly, the kernel weights are transformed into their matrix equivalent before deployment. The **left** figure below indicates how this is possible. The **right** figure shows how the input and kernel weights are transformed from 3D values to a matrix.\n",
    "\n",
    "Convolutions to Matrix Multiplies  |  Transforming Inputs and Weights\n",
    ":---------------------------------:|:-----------------------------------------:\n",
    "![](GEMMCalculations.png)             |  ![](GEMM_inputs_weights.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "### Overall Structure\n",
    "The streaming-CNN architecture's overall structure is shown **below**. The architecture accepts a streaming input with one sample entering at a time before being stored in a 'Block RAM buffer'. The 'Read and Write Controller' performs the matrix conversion and passes columns of the resulting matrix to the 'Matrix-Vector Multiplier'. The resulting data is then passed through a 'ReLU' activation before it is ready of the next layer to be processed.\n",
    "\n",
    "![](overall_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<!-- #### Optimisations in Matrix-Vector Multipliers\n",
    "\n",
    "Some of the matrix-vector multiplications can become quite large. We can take advantage of using a faster clock to time-share some of our resources. Below are two optimisations for both Convolutional and Dense neural network layers.\n",
    "\n",
    "On the **left** there is a fully parallel Matrix-Vector Multiplier for when the resulting input vector is small enough to run calulations in parallel. On the **right** is the serial-parallel Matrix-Vector Multiplier where a subset of the multiple-accumulates are time-shared to reduce the resources used.\n",
    "\n",
    "Fully Parallel Matrix-Vector Multiplier  |  Serial-Parallel Matrix-Vector Multiplier\n",
    ":---------------------------------------:|:-----------------------------------------:\n",
    "![](fullyparallel.png)                   |  ![](serial-parallel.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantisation\n",
    "The whole model runs with **18-bit fixed point** arithmetic for both inputs and weights. This value was chosen as it is the maximum fixed point length accepted by the DSP48s on-chip and maintains good precision of the original floating point weights.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Demo\n",
    "### Choose from 8 different modulation schemes and test out the CNN.\n",
    "Firstly, the input waveform is plotted. Next the prediction by the model compared to the actual label.\n",
    "Finally the prediction confidence by the CNN is displayed in the form of a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904e8843dcd544acadd037dc669b031c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Mods:', options=('8PSK', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amc_widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To activate Voila dashboard, run the following command\n",
    "# voila /home/xilinx/jupyter_notebooks/rfsoc_amc/voila_modulation_classification.ipynb --ExecutePreprocessor.timeout=180 --port=8866 --TagRemovePreprocessor.remove_cell_tags='{\"ignore_me\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
